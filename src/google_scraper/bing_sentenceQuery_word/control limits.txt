We studied big idea computing allows u perform amazing task information process
You might gotten impression quantify information design algorithm solve problem using computing
In chapter study theory limit computing
There theoretical practical limit computing u
When talk formal definition algorithm introduced mathematical model computation
With model study nature computing including possibly
Alan Turing contributed greatly computability theory model machine
He proved Turing machine powerful computer ever build
If find problem Turing machine solve proved solution computable
problem solvable computing computer
In Alan Turing proved general algorithm solve possible pair exist
halting problem unsolvable using computing
More specifically halting problem undecidable simplest type question answer yes decision question whether program eventually halt stop given input
Obviously infeasible actually run program input see whether halt may take forever infinite loop program
The idea analyze program given input determine whether halt
Alan Turing proved halting problem undecidable proof technique called
It would helpful review wikipedia
Another classic example proof number theory asserts infinitely many prime number
All proof contradiction start assumption proposition trying proof false follow logical sequence valid step arrive conclusion clearly false contradicts also false statement either true false never
If assume halting problem able design algorithm implement program solve problem u
The program take program input program input parameter return answer whether program halt input
Such program may sound strange take program input seen program
higher order function block Snap
take block program input date take source code program data run program
Programs data intrinsic difference tow
The following proof show program answer halting question exist
Here YouTube video illustrating proof Halting problem hard solvable algorithmically even principle
There hard problem solvable principle practice close impossible solve
As see categorize problem performance best known algorithm
If problem solved using fast algorithm problem easy use computer solve fast
On contrary best known algorithm know take long time solve problem hard computer solve fast
Using put algorithm particular category according algorithm complexity
If notation category contains polynomial term problem solvable using algorithm category called P problem Polynomial time solution exist
The P problem easy problem computer
Among problem without polynomial time solution problem guess solution verified polynomial time
For example prime decomposition problem known polynomial time solution given answer verify quickly simply multiplying factor comparing result integer
These type problem called NP Polynomial problem
Collectively call problem take long solve intractable problem include problem best algorithm exponential time polynomial time solution exponent larger

If problem best algorithmic solution computer operation per second would take year age universe solve problem computer
Obviously P subset NP NP defined polynomial answer verification time able solve problem polynomial time P certainly qualifies
Whether P proper subset NP word whether remains one open question computer science
Nobody know answer
You win million dollar solve one
To attack P
NP problem theoretical computer scientist defined another category called problem
The relationship among three category illustrated following figure
All problem category NP problem sharing one special property ALL problem problem polynomial time
Because nature solve ANY single problem category proved NP problem solvable polynomial time

We take NP problem translate solved problem solve problem polynomial time
The overall time still polynomial polynomial polynomial polynomial
Thousands discovered none solved
problem sense difficult known problem
Most computer scientist believe implication otherwise
The creative leap disappear solving problem easy able recognize right answer
Most encryption algorithm computationally secure breaking known efficient polynomial time solution
If encryption broken
There unsolved problem computer science
You find list problem

study theory experimentation engineering form basic design use computer
It scientific practical approach application systematic study feasibility structure expression mechanization methodical underlie acquisition representation processing storage communication access information
An alternate succinct definition computer science study automating algorithmic process scale
A specializes theory computation design computational system
Its field divided variety theoretical
Some field explores fundamental property intractable problem highly abstract field emphasize visual application
Other field still focus challenge implementing computation
For example considers various approach description computation study investigates various aspect use
considers challenge making computer computation useful usable human
The earliest foundation would become computer science predate invention modern
Machines calculating fixed numerical task existed since antiquity aiding computation multiplication division
Further performing computation existed since antiquity even development sophisticated computing equipment
designed constructed first working
In demonstrated digital mechanical calculator called
He may considered first computer scientist information theorist among reason documenting binary number system
In launched industry released simplified first calculating machine strong enough reliable enough used daily office environment
started design first eventually gave idea first
He started developing machine le two year sketched many salient feature modern computer
A crucial step adoption punched card system derived making infinitely programmable
In translation French article Analytical Engine wrote one many note included algorithm compute considered first computer program
Around invented used process statistical information eventually company became part
In one hundred year Babbage impossible dream convinced IBM making kind punched card equipment also calculator business develop giant programmable calculator based Babbage Analytical Engine used card central computing unit
When machine finished hailed Babbage dream come true
During new powerful machine developed term came refer machine rather human predecessor
As became clear computer could used mathematical calculation field computer science broadened study general
Computer science began established distinct academic discipline early
The world first computer science degree program began
The first computer science degree program United States formed
Since practical computer became available many application computing become distinct area study right
Although many initially believed impossible computer could actually scientific field study late fifty gradually became accepted among greater academic population
It brand formed part computer science revolution time
IBM short International Business Machines released IBM later IBM computer widely used exploration period device
Still working IBM computer frustrating misplaced much one letter one instruction program would crash would start whole process
During late computer science discipline much developmental stage issue commonplace
Time seen significant improvement usability effectiveness
Modern society seen significant shift user computer technology usage expert professional user base
Initially computer quite costly degree human aid needed efficient part professional computer operator
As computer adoption became widespread affordable le human assistance needed common usage
Despite short history formal academic discipline computer science made number fundamental contribution science fact along founding science current epoch human history called driver seen third major leap human technological progress CE BC
These contribution include Although first proposed term computer science appears article Louis Fein argues creation analogous creation justifying name arguing like subject applied interdisciplinary nature characteristic typical academic discipline
His effort others rewarded university went create program starting Purdue
Despite name significant amount computer science involve study computer
Because several alternative name proposed
Certain department major university prefer term emphasize precisely difference
Danish scientist suggested term reflect fact scientific discipline revolves around data data treatment necessarily involving computer
The first scientific institution use term Department Datalogy University Copenhagen founded Peter Naur first professor datalogy
The term used mainly Scandinavian country
An alternative term also proposed Naur used distinct field data analysis including statistic database
Also early day computing number term practitioner field computing suggested
Three month later journal suggested followed next year
The term also suggested
In Europe term derived contracted translation expression automatic information
informazione automatica Italian information mathematics often used
French German Italian Dutch Spanish Portuguese mean informatics
Similar word also adopted UK
In however linked applied computing computing context another domain
A folkloric quotation often attributed almost certainly first formulated state computer science computer astronomy telescope
The design deployment computer computer system generally considered province discipline computer science
For example study computer hardware usually considered part study commercial deployment often called information technology
However much idea various discipline
Computer science research also often intersects discipline philosophy
Computer science considered much closer relationship mathematics many scientific discipline observer saying computing mathematical science
Early computer science strongly influenced work mathematician continues useful interchange idea two field area
The relationship computer science software engineering contentious issue muddied term software engineering mean computer science defined
taking cue relationship engineering science discipline claimed principal focus computer science studying property computation general principal focus software engineering design specific computation achieve practical goal making two separate complementary discipline
The academic political funding aspect computer science tend depend whether department formed mathematical emphasis engineering emphasis
Computer science department mathematics emphasis numerical orientation consider alignment
Both type department tend make effort bridge field educationally across research
A number computer scientist argued distinction three separate paradigm computer science
argued paradigm science technology mathematics
working group argued theory abstraction modeling design
Amnon Eden described rationalist paradigm treat computer science branch mathematics prevalent theoretical computer science mainly employ technocratic paradigm might found engineering approach prominently software engineering scientific paradigm approach artifact empirical perspective identifiable branch
As discipline computer science span range topic theoretical study algorithm limit computation practical issue implementing computing system hardware software
formerly called Computing Sciences Accreditation made representative ACM IEEE CS four area considers crucial discipline computer science
In addition four area CSAB also identifies field software engineering artificial intelligence computer networking communication database system parallel computation distributed computation interaction computer graphic operating system numerical symbolic computation important area computer science
mathematical abstract spirit derives motivation practical everyday computation
Its aim understand nature consequence understanding provide efficient methodology
All study related mathematical logic formal concept method could considered theoretical computer science provided motivation clearly drawn field
Data structure algorithm study commonly used computational method computational efficiency
According fundamental question underlying computer science What efficiently automated
Theory computation focused answering fundamental question computed amount resource required perform computation
In effort answer first question examines computational problem solvable various theoretical
The second question addressed study time space cost associated different approach solving multitude computational problem
The famous problem one open problem theory computation
Information theory related quantification information
This developed find fundamental limit operation compressing data reliably storing communicating data
Coding theory study property system converting information one form another fitness specific application
Codes used recently also
Codes studied purpose designing efficient reliable method
Programming language theory branch computer science deal design implementation analysis characterization classification individual
It fall within discipline computer science depending affecting software engineering
It active research area numerous dedicated academic journal
Formal method particular kind based technique development software system
The use formal method software hardware design motivated expectation engineering discipline performing appropriate mathematical analysis contribute reliability robustness design
They form important theoretical underpinning software engineering especially safety security involved
Formal method useful adjunct software testing since help avoid error also give framework testing
For industrial use tool support required
However high cost using formal method mean usually used development safety utmost importance
Formal method best described application fairly broad variety fundamental particular calculus also problem software hardware specification verification
Computer architecture digital computer organization conceptual design fundamental operational structure computer system
It focus largely way central processing unit performs internally access address memory
The field often involves discipline computer engineering electrical engineering selecting interconnecting hardware component create computer meet functional performance cost goal
Computer performance analysis study work flowing computer general goal improving controlling using resource efficiently eliminating predicting performance anticipated peak load
Concurrency property system several computation executing simultaneously potentially interacting
A number mathematical model developed general concurrent computation including model
A distributed system extends idea concurrency onto multiple computer connected network
Computers within distributed system private memory information often exchanged among achieve common goal
This branch computer science aim manage network computer worldwide
Computer security branch computer technology whose objective includes protection information unauthorized access disruption modification maintaining accessibility usability system intended user
Cryptography practice study hiding encryption therefore deciphering decryption information
Modern cryptography largely related computer science many encryption decryption algorithm based computational complexity
A database intended organize store retrieve large amount data easily
Digital database managed using database management system store create maintain search data
Computer graphic study digital visual content involves synthesis manipulation image data
The study connected many field computer science including heavily applied field special effect
Research develops theory principle guideline user interface designer create satisfactory user experience desktop laptop mobile device
field study concerned constructing technique using computer analyze solve problem
In practical use typically application form problem various scientific discipline
Artificial intelligence AI aim required synthesize process environmental adaptation learning communication found human animal
From origin artificial intelligence research necessarily drawing area expertise
AI associated popular mind main field practical application embedded component area require computational understanding
The late question Can computer think
question remains effectively unanswered although still used ass computer output scale human intelligence
But automation evaluative predictive task increasingly successful substitute human monitoring intervention domain computer application involving complex data
Software engineering study designing implementing modifying software order ensure high quality affordable maintainable fast build
It systematic approach software design involving application engineering practice software
Software engineering deal organizing analyzing deal creation manufacture new software internal maintenance arrangement
Both computer application software engineer computer system software engineer projected among fastest growing occupation
The philosopher computing noted three Conferences important event computer science research
During conference researcher public private sector present recent work meet
Unlike academic field computer science prestige greater journal publication
One proposed explanation quick development relatively new field requires rapid review distribution result task better handled conference journal
Since computer science relatively new field widely taught school university academic subject
For example estimated percent high school United States offered computer science education
A report Association Computing Machinery ACM Computer Science Teachers Association CSTA revealed state adopted significant education standard high school computer science
However computer science education growing
Some country Israel New Zealand South Korea already included computer science respective national secondary education curriculum
Several country following suit
In country significant gender gap computer science education
For example US computer science degree conferred woman
This gender gap also exists Western country
However part world gap small nonexistent
In approximately half computer science degree conferred woman
In woman made computer science graduate


Your browser old version Safari fully supported Quizlet
Please download newer web browser improve experience

Given expansive growth field become challenging discern belongs modern computer science degree
My faculty engaging debate I coalesced thought answer question What every computer science major know
I tried answer question conjunction four concern My thought factor general principle specific recommendation relevant modern computing landscape
Computer science major feel free use guide
Please email suggestion addition deletion
Thanks suggestion reminder
I incorporate I receive keep living document
Having emerged engineering mathematics computer science program take approach hiring graduate
A say nothing programmer ability
Every computer science major build
A portfolio could simple personal blog post project accomplishment
A better portfolio would include page publicly browsable code hosted perhaps github Google code
Contributions open source linked documented
A code portfolio allows employer directly judge ability
GPAs resume
Professors design course project impress portfolio student conclusion course take time update
Lone wolf computer science endangered specie
Modern computer scientist must practice persuasively clearly communicating idea
In smaller company whether programmer communicate idea management may make difference company success failure
Unfortunately something fixed addition single class although solid course technical communication hurt
More class need provide student opportunity present work defend idea oral presentation
I would recommend student master presentation tool like PowerPoint favorite Keynote
Sorry much I love presentation tool static
For producing beautiful mathematical documentation LaTeX equal
All written assignment technical course submitted LaTeX
Computer science quite engineering
But close enough
Computer scientist find working engineer
Computer scientist traditional engineer need speak language language rooted real analysis linear algebra probability physic
Computer scientist ought take physic electromagnetism
But need take multivariate calculus differential equation good measure
In constructing sound simulation command probability often time linear algebra invaluable
In interpreting result substitute solid understanding statistic
Computer scientist comfortable practiced Unix philosophy computing
The Unix philosophy opposed Unix one emphasizes linguistic abstraction composition order effect computation
In practice mean becoming comfortable notion computing configuration software development
Given prevalence Unix system computer scientist today fluent basic Unix including ability Students reject Unix philosophy unless understand power
Thus best challenge student complete useful task Unix comparative advantage Some computer scientist sneer system administration IT task
The thinking computer scientist teach anything technician
This true
In theory
Yet attitude misguided computer scientist must able competently securely administer system network
Many task software development efficiently executed without passing system administrator
Every modern computer scientist able Programming language rise fall solar cycle
A programmer career
While important teach language relevant employer equally important student learn teach new language
The best way learn learn progamming language learn multiple programming language programming paradigm
The difficulty learning th language half difficulty th
Yet understand programming language one must implement one
Ideally every computer science major would take compiler class
At minimum every computer science major implement interpreter
The following language provide reasonable mixture paradigm practical application Racket dialect Lisp aggressively simple syntax
For small fraction student syntax impediment
To blunt student fundamental mental barrier accepting alien syntactic regime even temporarily lack mental dexterity survive career computer science
Racket powerful macro system facility programming thoroughly erase line data code
If taught correctly Lisp liberates
C terse unforgiving abstraction silicon
C remains without rival programming embedded system
Learning C imparts deep understanding dominant von Neumann architecture way language
Given intimate role poor C programming play prevalence buffer overflow security vulnerability critical programmer learn program C properly
JavaScript good representative semantic model popular dynamic language Python Ruby Perl
As native language web pragmatic advantage unique
Squeak modern dialect Smalltalk purest language
It imparts essence
Java remain popular long ignore
Standard ML clean embodiment system
The type system one greatest yet achievement modern computing
Though exponential complexity type inference always fast program human interest
The type system rich enough allow expression complex structural invariant
It rich fact program often
Though niche application logic programming alternate paradigm computational thinking
It worth understanding logic programming instance programmer may need emulate within another paradigm
Another logic language worth learning
miniKanren stress pure cut allowed logic programming
This constraint evolved alternate style logic programming called relational programming grant property typically enjoyed Prolog program
Scala fusion functional programming language
Scala Java
Built atop Java Virtual Machine compatible existing Java codebases stand likely successor Java
Haskell crown jewel family language
Fully exploiting laziness Haskell come closest programming pure mathematics major programming language
necessary evil
But since must taught must taught full
In particular computer science major leave grasp even
Any assembly language
Since popular might well
Learning compiler best way learn assembly since give computer scientist intuitive sense code transformed
Computer scientist understand generative programming macro lexical dynamic scope closure continuation function dynamic dispatch subtyping module functors monad semantic concept distinct specific syntax
Computer scientist must solid grasp formal logic proof
Proof algebraic manipulation natural deduction engages reasoning common routine programming task
Proof induction engages reasoning used construction recursive function
Computer scientist must fluent formal mathematical notation reasoning rigorously basic discrete structure set tuples sequence function power set
For computer scientist important cover reasoning Students learn enough number theory study implement common cryptographic protocol
Students certainly see common rare yet unreasonably effective data structure algorithm
But important knowing specific algorithm data structure usually easy enough look computer scientist must understand design algorithm greedy dynamic strategy span gap algorithm ideal implementation
At minimum computer scientist seeking stable employment know following Computer scientist ready implement extend algorithm operates data structure including ability search element add element remove element
For completeness computer scientist know imperative functional version algorithm
A grasp theory prerequisite research graduate school
Theory invaluable provides hard boundary problem provides mean circumventing initially appear hard boundary
Computational complexity legitimately claim one truly predictive theory computer science
A computer scientist know boundary tractability computability lie
To ignore limit invite frustration best case failure worst
At undergraduate level theory cover least model computation computational complexity
Models computation cover automaton regular language regular expression pushdown automaton language formal grammar Turing machine lambda calculus undecidability
At undergraduate level student learn least enough complexity understand difference P NP
To avoid leaving wrong impression student solve large problem NP reduction SAT use modern SAT solver
There substitute solid understanding computer architecture
Computer scientist understand computer transistor
The understanding architecture encompass standard level abstraction transistor gate adder muxes flip flop ALUs control unit cache RAM
An understanding GPU model computing important foreseeable future
A good understanding cache bus hardware memory management essential achieving good performance modern system
To get good grasp machine architecture student design simulate small CPU
Any sufficiently large program eventually becomes operating system
As computer scientist aware kernel handle system call paging scheduling filesystems internal resource management
A good understanding operating system secondary understanding compiler architecture achieving performance
Understanding operating system I would interpret liberally include runtime system becomes especially important programming embedded system without one
It important student get hand dirty real operating system
With Linux virtualization easier ever
To get better understanding kernel student could Given ubiquity network computer scientist firm understanding network stack routing protocol within network
The mechanic building efficient reliable transmission protocol like TCP top unreliable transmission protocol like IP magic computer scientist
It core knowledge
Computer scientist must understand involved protocol design example choose TCP choose UDP
Programmers need understand larger social implication congestion use UDP large scale well
Given frequency modern programmer encounter network programming helpful know protocol existing standard Computer scientist understand exponential back packet collision resolution mechanism involved congestion control
Every computer scientist implement following No student ever pas intro neworking class without sniffing instructor Google query
It probably going far require student implement reliable transmission protocol scratch atop IP I say personally transformative experience student
The sad truth security majority security vulnerability come sloppy programming
The sadder truth many school poor job training programmer secure code
Computer scientist must aware mean program compromised
They need develop sense defensive programming mind thinking code might attacked
Security kind training best distributed throughout entire curriculum discipline warn student native vulnerability
At minimum every computer scientist need understand A reader pointed computer scientist also need aware basic IT security measure choose legitimately good password properly configure firewall iptables
Cryptography make much digital life possible
Computer scientist understand able implement following concept well common pitfall Since common fault implementation cryptosystems every computer scientist know acquire random number task hand
At least nearly every data breach shown computer scientist need know salt hash password storage
Every computer scientist pleasure breaking ciphertext using cryptosystems statistical tool
RSA everyone
Every student create digital certificate set http apache
It surprisingly arduous
Student also write console web client connects SSL
As strictly practical matter computer scientist know use GPG use authentication ssh encrypt directory hard disk
Software testing must distributed throughout entire curriculum
A course software engineering cover basic style testing substitute practicing art
Students graded test case turn
I use test case turned student student
Students seem care much developing defensive test case unleash hell come sandbagging classmate
Programmers often write software programmer worse
User interface design broadly user experience design might underappreciated aspect computer science
There misconception even among professor user experience soft skill ca taught
In reality modern user experience design anchored principle human factor engineering industrial design
If nothing else computer scientist know interface need make ease executing task proportional frequency task multiplied importance
As practicality every programmer comfortable designing usable web interface HTML CSS JavaScript
Good visualization rendering data fashion human perceive information
This easy thing
The modern world sea data exploiting local maximum human perception key making sense
Parallelism back uglier ever
The unfortunate truth harnessing parallelism requires deep knowledge architecture multicore cache bus GPUs etc
And practice
Lots practice
It clear final answer parallel programming solution emerged
For student learn CUDA OpenCL
Threads flimsy abstraction parallelism particularly cache cache coherency involved
But thread popular tricky worth learning
Pthreads reasonably portable thread library learn
For anyone interested parallelism MPI prerequisite
On principle side seem enduring
The principle software engineering change fast programming language
A good course practice team software construction provides working knowledge pitfall inherent endeavor
It recommended several reader student break team three role leader rotating three different project
Learning attack maneuver large existing codebase skill programmer master one best learned school instead job
All student need understand centralized version control system like svn distributed version control system like git
A working knowlege debugging tool like gdb valgrind go long way finally become necessary
As demand secure reliable software increase formal method may one day end mean delivering
At present formal modeling verification software remains challenging progress field steady get easier every year
There may even come day within lifetime computer science major formal software construction expected skill
Every computer scientist least moderately comfortable using one theorem prover
I think matter one
Learning use theorem prover immediately impact coding style
For example one feel instinctively allergic writing statement cover possibility
And writing recursive function user theorem provers strong urge eliminate
There discipline dominated clever graphic
The field driven toward even defined good enough
As better way teach clever programming solid appreciation optimizing effort graphic simulation
Over half coding hack I learned came study graphic
Simple ray tracer constructed line code
It good mental hygiene work transformation necessary perform perspective projection wireframe engine
Data structure like BSP tree algorithm like rendering great example clever design
In graphic simulation many
Robotics may one engaging way teach introductory programming
Moreover cost robotics continues fall threshold passed enable personal robotics revolution
For program unimaginable degree personal physical automation horizon
If reason outsized impact early history computing computer scientist study artificial intelligence
While original dream intelligent machine seems far artificial intelligence spurred number practical field machine learning data mining natural language processing
Aside outstanding technical merit sheer number job opening relevance engineer indicates every computer scientist grasp fundamental machine learning
Machine learning doubly emphasizes need understanding probability statistic
At undergraduate level core concept include Bayesian network clustering learning
Databases common useful ignore
It useful understand fundamental data structure algorithm power database engine since programmer often enough reimplement database system within larger software system
Relational algebra relational calculus stand exceptional success story model computation
Unlike UML modeling ER modeling seems reasonable mechanism visualing encoding design constraint upon software artifact
A computer scientist set operate LAMP stack one good idea lot hard work away running company
My suggestion limited blind spot knowledge
What I listed included

We seen one function already output message
To use function always write name followed parenthesis
The word basically mean input function
Then function action depending argument
When multiple argument function separate comma
For example give multiple argument print order space separating
We demonstrate example
A function may also give back value like output
For example function short give back largest argument must number
The function friend behaves similarly function return smallest argument
Functions combined create complicated expression
You limited using function Python
In lesson learn define new function
If call function enough argument input many argument get error
For example requires least one input It important carefully read error get back code work
Python usually give helpful feedback went wrong
However sometimes need look around little bit diagnose problem example
Python say syntax error mean ca understand trying This exercise using function
There connection city Maxime Miniac several bridge
There separate limit amount weight transported across bridge
In order drive along route truck need drive first bridge weight limit one weight limit one weight limit
Your truck crash overload three weight limit
Your code assume variable already contain bridge weight limit
Your truck take either route
Write program print maximum weight transported two city
Assume variable contain bridge weight limit
Here another code scramble must line rearrange correct program
Once finish exercise two choice Create free account login save progress

In execution smallest sequence programmed instruction managed independently typically part
The implementation thread differs operating system case thread component process
Multiple thread exist within one process executing sharing resource different process share resource
In particular thread process share executable code value variable given time
Systems single processor generally implement multithreading CPU switch different
This generally happens often rapidly enough user perceive thread task running parallel
On system multiple thread execute every processor core executing separate thread simultaneously processor core separate software thread also executed concurrently separate hardware thread
Threads made early appearance MVT context called task
The term thread attributed
many modern operating system directly support multiprocessor threading allows programmer manipulate thread exposing required functionality interface
Some threading implementation called whereas LWP specific type kernel thread share state information
Furthermore program threading timer signal method interrupt execution performing sort time slicing
Threads differ traditional operating system Systems said thread process operating system great difference except cost switch architecture notably result TLB flush
In one time
The opposite multithreading
While suggested term misleading term widely accepted within community
Multithreading mainly found multitasking operating system
Multithreading widespread programming execution model allows multiple thread exist within context one process
These thread share process resource able execute independently
The threaded programming model provides developer useful abstraction concurrent execution
Multithreading also applied one process enable system
Multithreaded application following advantage Multithreading following drawback Operating system schedule thread either cooperatively
On widely used approach finer grained control execution time via
However preemptive scheduling may context switch thread moment unanticipated programmer therefore causing
In contrast relies thread relinquish control execution thus ensuring thread
This create problem cooperatively multitasked thread waiting thread yielding control execution intensive computation
Until early desktop computer one CPU support although thread still used computer switching thread generally still quicker
In added support processor name introduced processor introduced processor
Processors higher requirement behavior might support multithreading decreasing time perhaps allocating dedicated thread instead common register file
Scheduling done kernel level user level multitasking done preemptively cooperatively
This yield variety related concept
At kernel level contains one share process resource memory file handle process unit resource thread unit scheduling execution
Kernel scheduling typically uniformly done preemptively le commonly cooperatively
At user level process schedule multiple thread execution
If share data Erlang usually analogously called process share data usually called particularly preemptively scheduled
Cooperatively scheduled user thread known different process may schedule user thread differently
User thread may executed kernel thread various way
The term variously refers user thread kernel mechanism scheduling user thread onto kernel thread
A heavyweight unit kernel scheduling creating destroying switching process relatively expensive
Processes allocated operating system
Resources include memory code data socket device handle window
Processes share address space file resource except explicit method inheriting file handle shared memory segment mapping file shared way see
Creating destroying process relatively expensive resource must acquired released
Processes typically preemptively multitasked process switching relatively expensive beyond basic cost due issue cache flushing
A lightweight unit kernel scheduling
At least one kernel thread exists within process
If multiple kernel thread exist within process share memory file resource
Kernel thread preemptively multitasked operating system process preemptive
Kernel thread resource except copy including thus relatively cheap create destroy
Thread switching also relatively cheap requires context switch saving restoring register stack pointer change virtual memory thus leaving TLB valid
The kernel assign one thread logical core system processor split multiple logical core support multithreading support one logical core per physical core swap thread get blocked
However kernel thread take much longer user thread swapped
Threads sometimes implemented library thus called
The kernel unaware managed scheduled
Some implementation base user thread top several kernel thread benefit machine
In article term thread without kernel user qualifier default referring kernel thread
User thread implemented also called
User thread generally fast create manage take advantage multithreading multiprocessing get blocked associated kernel thread get blocked even user thread ready run
even lighter unit scheduling running fiber must explicitly allow another fiber run make implementation much easier kernel
A fiber scheduled run thread process
This permit application gain performance improvement managing scheduling instead relying kernel scheduler may tuned application
Parallel programming environment typically implement task fiber
Closely related fiber distinction coroutines construct fiber construct
Threads process share address space
This allows concurrently running code tightly conveniently exchange data without overhead complexity
When shared thread however even simple data structure become prone require one CPU instruction update two thread may end attempting update data structure time find unexpectedly changing underfoot
Bugs caused race condition difficult reproduce isolate
To prevent threading APIs offer data structure concurrent access
On uniprocessor system thread running locked mutex must sleep hence trigger context switch
On system thread may instead poll mutex
Both may sap performance force processor SMP system contend memory bus especially locking fine
Although thread seem small step sequential computation fact represent huge step
They discard essential appealing property sequential computation understandability predictability determinism
Threads model computation wildly job programmer becomes one pruning nondeterminism
User thread fiber implementation typically entirely
As result context switching user thread fiber within process extremely efficient require interaction kernel context switch performed locally saving CPU register used currently executing user thread fiber loading register required user thread fiber executed
Since scheduling occurs userspace scheduling policy easily tailored requirement program workload
However use blocking system call user thread opposed kernel thread fiber problematic
If user thread fiber performs system call block user thread fiber process unable run system call return
A typical example problem performing program written perform synchronously
When operation initiated system call made return operation completed
In intervening period entire process blocked kernel run starves user thread fiber process executing
A common solution problem providing API implement synchronous interface using internally scheduling another user thread fiber operation progress
Similar solution provided blocking system call
Alternatively program written avoid use synchronous blocking system call
implemented LWPs
implement LWPs kernel thread model
SunOS SunOS well NetBSD NetBSD implemented two level model multiplexing one user level thread kernel thread M N model
SunOS later well NetBSD eliminated user thread support returning model
FreeBSD implemented M N model
FreeBSD supported M N user could choose one used given program using
Starting FreeBSD became default
FreeBSD longer support M N model
The use kernel thread simplifies user code moving complex aspect threading kernel
The program need schedule thread explicitly yield processor
User code written familiar procedural style including call blocking APIs without starving thread
However kernel threading may force context switch thread time thus expose race hazard concurrency would otherwise lie latent
On SMP system exacerbated kernel thread may literally execute separate processor parallel
Threads created user correspondence schedulable entity kernel simplest possible threading implementation
used approach start implement approach via older
This approach also used
An model implies thread map one scheduled entity kernel knowledge application thread
With approach context switching done quickly addition implemented even simple kernel support threading
One major drawback however benefit hardware acceleration processor computer never one thread scheduled time
For example If one thread need execute request whole process blocked threading advantage used
The us threading
M N map M number application thread onto N number kernel entity virtual processor
This compromise threading
In general M N threading system complex implement either kernel user thread change kernel code required
In M N implementation threading library responsible scheduling user thread available schedulable entity make context switching thread fast avoids system call
However increase complexity likelihood well suboptimal scheduling without extensive expensive coordination userland scheduler kernel scheduler
Fibers implemented without operating system support although operating system library provide explicit support
IBM F included support multithreading called late continued Optimizing Compiler later version
The IBM Enterprise compiler introduced new model thread API
Neither version part standard
Many programming language support threading capacity
Many implementation support threading provide access native threading APIs operating system
Some usually programming language language expose threading developer abstracting platform specific difference threading implementation runtime
Several programming language language extension also try abstract concept concurrency threading developer fully MPI
Some language designed sequential parallelism instead especially using GPUs without requiring concurrency thread
A interpreted programming language implementation Ruby Python support threading concurrency parallel execution thread due GIL
The GIL mutual exclusion lock held interpreter prevent interpreter simultaneously interpreting application code two thread effectively limit parallelism multiple core system
This limit performance mostly thread require processor much one
Other implementation interpreted programming language using Thread extension avoid GIL limit using Apartment model data code must explicitly shared thread
In Tcl thread one interpreter
different threading model support extremely large number thread modeling hardware
A standardized interface thread implementation Pthreads set library call
OS vendor free implement interface desired application developer able use interface across multiple platform
Most platform including Linux support Pthreads
Microsoft Windows set thread function interface multithreading like
Java provides yet another standardized interface host operating system using library
Multithreading library provide function call create new thread take function parameter
A concurrent thread created start running passed function end function return
The thread library also offer synchronization function make possible implement free multithreading function using condition variable synchronization primitive
Another paradigm thread usage set number thread created startup wait task assigned
When new task arrives wake completes task go back waiting
This avoids relatively expensive thread creation destruction function every task performed take thread management application developer hand leaf library operating system better suited optimize thread management
For example framework like
In programming model designed array thread run parallel using ID find data memory
In essence application must designed thread performs operation different segment memory operate parallel use GPU architecture

There several physical practical limit amount performed given amount mass volume energy Several method proposed producing computing device data storage device approach physical practical limit In field theoretical computational problem often
Computability theory describes degree problem computable whereas complexity theory describes asymptotic degree resource consumption
Computational problem therefore confined
The classify degree problem respectively computable computable polynomial time
For instance level arithmetical hierarchy classifies computable partial function
Moreover hierarchy strict class arithmetic hierarchy classifies strictly function
Many limit derived term physical constant abstract model computation Computer Science loose
Very known limit directly obstruct technology many engineering obstacle currently explained limit

